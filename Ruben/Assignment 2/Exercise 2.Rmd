---
title: "Exercise 2"
author: "Ruben van den Goorbergh"
date: "10/27/2020"
output: html_document
---
Session info
```{r}
sessionInfo()
```

## 1 Aim 
In this simulation study I aim to show that the analytically derived result of a z-test for difference in means (with known population standard deviation) is the same as the empirical result obtained by simulation.

Consider a situation where two group means are found: $\bar{X}_1 = 5, \bar{X}_2 = 4.8$, we also know that the standard deviation for both groups is 1: $\sigma_1 = 1, \sigma_2 = 1$ and the sample size per group is 100. The question is whether the population mean of group 1 is larger than the population mean of group 2.


## Analytical results 
To obtain the analytical results for this problem, we would specify the following hyptheses: $$H_0: \mu_1 = \mu_2 $$ $$H_a: \mu_1 > \mu_2$$.

To arrive at a z score, the following formula can be used: 
$$z = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_1}}}$$
Filling this in leads to the following result:
$$\frac{5 - 4.8}{\sqrt{\frac{1}{100}+\frac{1}{100}}} = 1.414$$
This z-score corresponds to a probability of ~0.92, meaning that if we would repeat this experiment many times, in 92% of the cases we would find cases with a difference smaller than 0.2, assuming that $H_0$ is true. Depending on the significance level we would conclude that there is no significance difference in means ($e.g. when \alpha = 0.05$) or that there is a significant difference in means ($e.g. when  \alpha =0.1$).

## 2 Set up

### 2.1 Fix random seed 
Fixing a seed to make sure the results are reproducible. This is necesarry because I will make use of a random number generator.
```{r}
set.seed(666)
```

### 2.2 Number of simulations 
```{r}
numsim <- 10000
n <- 100
```

### 2.3 Packages used
```{r}
library(tidyverse)
```

## Simulation

To see what would happen if we would actually repeated the experiment many times under $H_0$, a simple simulation study was designed

First we create 2 vectors to store the sample means of the both groups.
```{r}
means_h0 <- rep(NA, numsim)
means_ha <- rep(NA, numsim)
```

Then we sample the means for 2 groups from a normal distribution, both with sample size n, a mean of 0 and a standard deviation of 1. Binding them in a dataframe.
```{r}
for (i in 1:numsim){
  means_h0[i] <- mean(rnorm(n = n, mean = 0, sd = 1))
  means_ha[i] <- mean(rnorm(n = n, mean = 0, sd = 1))
}

data <- as.data.frame(cbind(means_h0,means_ha))
```

To give an impression of the sampling distribution of both groups, two overlaying histograms were plotted.
```{r}
ggplot(data = data) +
  geom_histogram(aes(x = means_h0, col = 'red'),alpha = 0.4) +
  geom_histogram(aes(x = means_ha, col = 'blue'), alpha = 0.4)
```

Then we create a new variable: difference in means. Then we plot the distibution of the mean differences, adding a line at 0.2.
```{r}
data <- data %>% 
  mutate(mean_dif = (means_ha - means_h0))

data %>% 
  ggplot()+
  geom_histogram(aes(x = mean_dif, col = 'red'), alpha = 0.4) +
  geom_vline(xintercept = 0.2)
```
The area of the distribution more extreme than 0.2 seems to we quite right. To be more precise, we can calculate the proportion of more extreme cases. We see that we get the same result as from the analytical method.
```{r}
mean(data$mean_dif > 0.2)
```




